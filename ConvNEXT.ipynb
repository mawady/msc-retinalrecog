{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvNEXT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "v6T0uIkA2aCq",
        "EUYkqdpb36sN",
        "PVBi7oXg3-G1"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOv8A6+1JnkXMToFKDbqCKe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNEXT for DR detection"
      ],
      "metadata": {
        "id": "BqTdYbiDufny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "v6T0uIkA2aCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Access"
      ],
      "metadata": {
        "id": "FqjI4jX32eZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wasxZn3ue1t",
        "outputId": "fdfcfff5-4f00-4a7b-fc53-a5e9d866d3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CWD: /content/drive/My Drive/University Of Stirling/Dissertation/ConvNEXT/APTOS2019\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Parameters\n",
        "DATASET_PATH = '/content/drive/My Drive/University Of Stirling/Dissertation/ConvNEXT/APTOS2019'\n",
        "PREP_PATH = DATASET_PATH + \"/preprocessed/\"\n",
        "\n",
        "# Load Dataset From Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(DATASET_PATH)\n",
        "print(\"CWD:\",os.getcwd())\n",
        "\n",
        "if not os.path.exists(PREP_PATH):\n",
        "  os.mkdir(PREP_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup"
      ],
      "metadata": {
        "id": "7En8mOAo3LJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "git clone https://github.com/facebookresearch/ConvNeXt\n",
        "pip install timm==0.3.2 tensorboardX six\n",
        "pip install submitit"
      ],
      "metadata": {
        "id": "6H8RHXnH3N2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and global parameters"
      ],
      "metadata": {
        "id": "ifpMFFxX2lkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "metadata": {
        "id": "M8h_iHOx2sX5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224,224)"
      ],
      "metadata": {
        "id": "c4XnQDs22u1c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation"
      ],
      "metadata": {
        "id": "fIl8zMTjz05Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(DATASET_PATH + \"/train.csv\")\n",
        "\n",
        "# ref: https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy/notebook\n",
        "# ref: https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy/notebook\n",
        "# ref for circle crop: https://github.com/debayanmitra1993-data/Blindness-Detection-Diabetic-Retinopathy-/blob/master/research_paper_implementation.ipynb\n",
        "def crop_image_from_gray(img,tol=7):\n",
        "    if img.ndim ==2:\n",
        "        mask = img>tol\n",
        "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "    elif img.ndim==3:\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        mask = gray_img>tol\n",
        "        \n",
        "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
        "            return img # return original image\n",
        "        else:\n",
        "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "            img = np.stack([img1,img2,img3],axis=-1)\n",
        "        return img\n",
        "\n",
        "def circle_crop(img, sigmaX = 30):   \n",
        "    \"\"\"\n",
        "    Create circular crop around image centre    \n",
        "    \"\"\"    \n",
        "    img = crop_image_from_gray(img)    \n",
        "    \n",
        "    height, width, depth = img.shape    \n",
        "    \n",
        "    x = int(width/2)\n",
        "    y = int(height/2)\n",
        "    r = np.amin((x,y))\n",
        "    \n",
        "    circle_img = np.zeros((height, width), np.uint8)\n",
        "    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n",
        "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
        "    img = crop_image_from_gray(img)\n",
        "    return img \n",
        "\n",
        "def preprocess(id_code):\n",
        "  path = DATASET_PATH + \"/train_images/\" + id_code + \".png\"\n",
        "\n",
        "  if(os.path.isfile(path) == False):\n",
        "    print(id_code + \" does not exist!\")\n",
        "    return\n",
        "\n",
        "  img = cv2.imread(path)\n",
        "\n",
        "\n",
        "  # Circle crop\n",
        "  img = circle_crop(img)\n",
        "\n",
        "  # Resize the image\n",
        "  img = cv2.resize(img, (224, 224))\n",
        "\n",
        "  # Extract Green Channel\n",
        "  img[:,:,0] = 0\n",
        "  img[:,:,2] = 0\n",
        "\n",
        "  # Convert to Greyscale\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Apply Gaussian Blur\n",
        "  img = cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , 512/10) ,-4 ,128)\n",
        "  \n",
        "  # Perform histogram equalization\n",
        "\n",
        "  clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
        "  img = clahe.apply(img)\n",
        "\n",
        "  cv2.imwrite(PREP_PATH + id_code + \".png\", img)\n",
        "\n",
        "\n",
        "for id_code in dataset[\"id_code\"]:\n",
        "  preprocess(id_code) "
      ],
      "metadata": {
        "id": "IDgCkcf1z0NF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Folder Structure"
      ],
      "metadata": {
        "id": "EUYkqdpb36sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(DATASET_PATH + \"/train\"):\n",
        "  os.mkdir(DATASET_PATH + \"/train\")\n",
        "  os.mkdir(DATASET_PATH + \"/train/0\")\n",
        "  os.mkdir(DATASET_PATH + \"/train/1\")\n",
        "  os.mkdir(DATASET_PATH + \"/train/2\")\n",
        "  os.mkdir(DATASET_PATH + \"/train/3\")\n",
        "  os.mkdir(DATASET_PATH + \"/train/4\")\n",
        "\n",
        "if not os.path.exists(DATASET_PATH + \"/validation\"):\n",
        "  os.mkdir(DATASET_PATH + \"/validation\")\n",
        "  os.mkdir(DATASET_PATH + \"/validation/0\")\n",
        "  os.mkdir(DATASET_PATH + \"/validation/1\")\n",
        "  os.mkdir(DATASET_PATH + \"/validation/2\")\n",
        "  os.mkdir(DATASET_PATH + \"/validation/3\")\n",
        "  os.mkdir(DATASET_PATH + \"/validation/4\")\n",
        "\n",
        "if not os.path.exists(DATASET_PATH + \"/test\"):\n",
        "  os.mkdir(DATASET_PATH + \"/test\")\n",
        "  os.mkdir(DATASET_PATH + \"/test/0\")\n",
        "  os.mkdir(DATASET_PATH + \"/test/1\")\n",
        "  os.mkdir(DATASET_PATH + \"/test/2\")\n",
        "  os.mkdir(DATASET_PATH + \"/test/3\")\n",
        "  os.mkdir(DATASET_PATH + \"/test/4\")"
      ],
      "metadata": {
        "id": "Ts7ECngw3ax9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "PVBi7oXg3-G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "def prepare_dataset():  \n",
        "  # Train-test split\n",
        "  train, test = train_test_split(dataset, test_size=.2)\n",
        "  train, valid = train_test_split(train, test_size=.3)\n",
        "\n",
        "  for image in train.values:\n",
        "    shutil.copyfile(PREP_PATH + image[0] + \".png\", DATASET_PATH + \"/train/\" + str(image[1]) + \"/\" + image[0] + \".png\")\n",
        "\n",
        "  for image in valid.values:\n",
        "    shutil.copyfile(PREP_PATH + image[0] + \".png\", DATASET_PATH + \"/validation/\" + str(image[1]) + \"/\" + image[0] + \".png\")\n",
        "\n",
        "  for image in test.values:\n",
        "    shutil.copyfile(PREP_PATH + image[0] + \".png\", DATASET_PATH + \"/test/\" + str(image[1]) + \"/\" + image[0] + \".png\")\n",
        "  \n",
        "  return (train, valid, test)\n",
        "\n",
        "\n",
        "train, valid, test = prepare_dataset()\n",
        "\n",
        "print(train.shape, valid.shape, test.shape)\n"
      ],
      "metadata": {
        "id": "RCCbBSfe3pAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}