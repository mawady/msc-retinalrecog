{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNXYzocs6rOpa1hOD+0CJVO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "E-3AC8gTf57q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation"
      ],
      "metadata": {
        "id": "lbTQQFdsnaz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Global Parameters\n",
        "N_CLASSES = 5\n",
        "CLASSES = [ \"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative DR\" ]\n",
        "IMG_SIZE = (512, 512)"
      ],
      "metadata": {
        "id": "3yU_yp6anwQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup with Dataset Download (11G)"
      ],
      "metadata": {
        "id": "Qzt4VQdkiCWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "\n",
        "DATASET_PATH = '/content/APTOS2019'\n",
        "TRAIN_PATH = DATASET_PATH + \"/train_images/\"\n",
        "TEST_PATH = DATASET_PATH + \"/test_images/\"\n",
        "TRAIN_PREP_PATH = DATASET_PATH + \"/train_preprocessed/\""
      ],
      "metadata": {
        "id": "-2BqKPGyJuA3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1nAz6IUq9OJ309bgxXLz38zbDCKXnnb4r\n",
        "!unzip APTOS2019.zip"
      ],
      "metadata": {
        "id": "h9vO7I7aiV5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup with Google Drive Access"
      ],
      "metadata": {
        "id": "L5N-Yp5riZ0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij1-9B7rmv1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425e6a78-a6dd-494d-c2c4-3a4038a86be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "CWD: /content/drive/My Drive/University Of Stirling/Dissertation/retinal-rec/Datasets/APTOS2019\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Parameters\n",
        "DATASET_PATH = '/content/drive/My Drive/University Of Stirling/Dissertation/retinal-rec/Datasets/APTOS2019'\n",
        "TRAIN_PATH = DATASET_PATH + \"/train_images/\"\n",
        "TEST_PATH = DATASET_PATH + \"/test_images/\"\n",
        "TRAIN_PREP_PATH = DATASET_PATH + \"/train_preprocessed/\"\n",
        "\n",
        "# Load Dataset From Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(DATASET_PATH)\n",
        "print(\"CWD:\",os.getcwd())\n",
        "\n",
        "if not os.path.exists(TRAIN_PREP_PATH):\n",
        "  os.mkdir(TRAIN_PREP_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Dataset"
      ],
      "metadata": {
        "id": "QBM7O3Zoilhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Dataset\n",
        "train = pd.read_csv(DATASET_PATH + \"/train.csv\")\n",
        "test = pd.read_csv(DATASET_PATH + \"/test.csv\")"
      ],
      "metadata": {
        "id": "safrZRbiIrbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "9S2Bsa1nH-EF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is true that the background contrast has improved after histogram equalization. But compare the face of statue in both images. We lost most of the information there due to over-brightness. It is because its histogram is not confined to a particular region as we saw in previous cases (Try to plot histogram of input image, you will get more intuition).\n",
        "\n",
        "So to solve this problem, adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied."
      ],
      "metadata": {
        "id": "vlTSOmzldbfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ref: https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy/notebook\n",
        "# ref: https://www.kaggle.com/code/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy/notebook\n",
        "# ref for circle crop: https://github.com/debayanmitra1993-data/Blindness-Detection-Diabetic-Retinopathy-/blob/master/research_paper_implementation.ipynb\n",
        "def crop_image_from_gray(img,tol=7):\n",
        "    if img.ndim ==2:\n",
        "        mask = img>tol\n",
        "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "    elif img.ndim==3:\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        mask = gray_img>tol\n",
        "        \n",
        "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
        "            return img # return original image\n",
        "        else:\n",
        "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "            img = np.stack([img1,img2,img3],axis=-1)\n",
        "        return img\n",
        "\n",
        "def circle_crop(img, sigmaX = 30):   \n",
        "    \"\"\"\n",
        "    Create circular crop around image centre    \n",
        "    \"\"\"    \n",
        "    img = crop_image_from_gray(img)    \n",
        "    \n",
        "    height, width, depth = img.shape    \n",
        "    \n",
        "    x = int(width/2)\n",
        "    y = int(height/2)\n",
        "    r = np.amin((x,y))\n",
        "    \n",
        "    circle_img = np.zeros((height, width), np.uint8)\n",
        "    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n",
        "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
        "    img = crop_image_from_gray(img)\n",
        "    return img \n",
        "\n",
        "def preprocess(id_code):\n",
        "\n",
        "  #fig, ax = plt.subplots(1,6) \n",
        "\n",
        "  img = cv2.imread(TRAIN_PATH + id_code + \".png\")\n",
        "\n",
        "  #ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) \n",
        "  #ax[0].set_title(\"Original\") \n",
        "  #ax[0].axis('off')\n",
        "\n",
        "  # Circle crop\n",
        "  img = circle_crop(img)\n",
        "\n",
        "  # Resize the image\n",
        "  img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "  #ax[1].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) \n",
        "  #ax[1].set_title(\"Circle crop and resize\") \n",
        "  #ax[1].axis('off')\n",
        "\n",
        "  # Extract Green Channel\n",
        "  img[:,:,0] = 0\n",
        "  img[:,:,2] = 0\n",
        "\n",
        "  #ax[2].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) \n",
        "  #ax[2].set_title(\"Green Channel Extraction\") \n",
        "  #ax[2].axis('off')\n",
        "\n",
        "  # Convert to Greyscale\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  #ax[3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) \n",
        "  #ax[3].set_title(\"Greyscale\") \n",
        "  #ax[3].axis('off')\n",
        "\n",
        "  # Apply Gaussian Blur\n",
        "  img = cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , 512/10) ,-4 ,128)\n",
        "  \n",
        "  #ax[4].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) \n",
        "  #ax[4].set_title(\"Gaussian Blur\") \n",
        "  #ax[4].axis('off')\n",
        "\n",
        "  # Perform histogram equalization\n",
        "\n",
        "  clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
        "  img = clahe.apply(img)\n",
        "\n",
        "  #ax[5].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) \n",
        "  #ax[5].set_title(\"Adaptive Histogram Equalization\") \n",
        "  #ax[5].axis('off')\n",
        "\n",
        "  cv2.imwrite(TRAIN_PREP_PATH + id_code + \".png\", img)\n",
        "\n",
        "\n",
        "#preprocess(\"0dc8d25b3f69\") # Level 3\n",
        "\n",
        "for id_code in train[\"id_code\"]:\n",
        "  preprocess(id_code) "
      ],
      "metadata": {
        "id": "1HbGwucTGqVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "it-9-8E0l7XN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}